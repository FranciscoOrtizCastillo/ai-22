{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Red neuronal secuencial\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Capa completamente conectada\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "# Optimizador\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5533599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asegurar que los resultados sean \"reproducibles\"\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8edabba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820ed6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_num(in_data):\n",
    "    \"\"\"Genera un gráfico que muestra un registro\n",
    "    del set de datos.\n",
    "    Para ello, convierte el array de 1 dimensión en\n",
    "    una matriz de 28x28.\n",
    "    \"\"\"\n",
    "    matriz = np.array(in_data.values)\n",
    "    plt.imshow(matriz.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd7110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: 200, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "registro = 200\n",
    "print(y_train.iloc[registro])\n",
    "mostrar_num(X_train.iloc[registro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d98159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4461973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 19:17:40.196783: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Crear red neuronal \n",
    "nn_squencial = Sequential([\n",
    "    layers.Input(784),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2d9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_squencial.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7570ccc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 12.9076 - accuracy: 0.5465 - val_loss: 0.8292 - val_accuracy: 0.6707\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 0.7164 - accuracy: 0.7830 - val_loss: 0.7526 - val_accuracy: 0.7987\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.8274 - val_loss: 0.5918 - val_accuracy: 0.8507\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8572 - val_loss: 0.6426 - val_accuracy: 0.8453\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.8578 - val_loss: 0.6182 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.8576 - val_loss: 0.5141 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.8662 - val_loss: 0.5797 - val_accuracy: 0.8520\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8739 - val_loss: 0.5065 - val_accuracy: 0.8587\n",
      "Epoch 9/10\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8747 - val_loss: 0.5660 - val_accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "211/211 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.8717 - val_loss: 0.5482 - val_accuracy: 0.8360\n"
     ]
    }
   ],
   "source": [
    "historial = nn_squencial.fit(\n",
    "    X_train.values,\n",
    "    y_train.values,\n",
    "    epochs=10,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddca3f",
   "metadata": {},
   "source": [
    "# Redes neuronales convolucionales\n",
    "\n",
    "![cnn1](cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2419c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5435fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a74bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train = X_train.values.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c573b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 8.2392 - accuracy: 0.5009 - val_loss: 0.4525 - val_accuracy: 0.8520\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.7273 - accuracy: 0.7616 - val_loss: 0.2607 - val_accuracy: 0.9147\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.5630 - accuracy: 0.8193 - val_loss: 0.1914 - val_accuracy: 0.9307\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.5166 - accuracy: 0.8310 - val_loss: 0.1748 - val_accuracy: 0.9467\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.4482 - accuracy: 0.8587 - val_loss: 0.1677 - val_accuracy: 0.9587\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.4265 - accuracy: 0.8676 - val_loss: 0.1161 - val_accuracy: 0.9600\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.4224 - accuracy: 0.8668 - val_loss: 0.1290 - val_accuracy: 0.9613\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.4028 - accuracy: 0.8686 - val_loss: 0.1437 - val_accuracy: 0.9547\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.4034 - accuracy: 0.8719 - val_loss: 0.1363 - val_accuracy: 0.9520\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.3947 - accuracy: 0.8754 - val_loss: 0.1493 - val_accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb374fc3490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_nn.fit(\n",
    "    new_x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10, validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84379ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_nn.save('conv_nn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
